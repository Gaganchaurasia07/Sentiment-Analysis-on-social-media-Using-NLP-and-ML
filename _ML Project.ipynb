{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f49736d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874cc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc26d1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4  The Swedish buyout firm has sold its remaining...   neutral"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b95c3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>Nordic Walking was first used as a summer trai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>According shipping company Viking Line , the E...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment\n",
       "5837  RISING costs have forced packaging producer Hu...  negative\n",
       "5838  Nordic Walking was first used as a summer trai...   neutral\n",
       "5839  According shipping company Viking Line , the E...   neutral\n",
       "5840  In the building and home improvement trade , s...   neutral\n",
       "5841  HELSINKI AFX - KCI Konecranes said it has won ...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c97081df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5842, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b48667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence', 'Sentiment'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912ad74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d25d49ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence     0\n",
       "Sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7026bb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5842 entries, 0 to 5841\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Sentence   5842 non-null   object\n",
      " 1   Sentiment  5842 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 91.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d367f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5842</td>\n",
       "      <td>5842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5322</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Managing Director 's comments : `` Net sales f...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>3130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentence Sentiment\n",
       "count                                                5842      5842\n",
       "unique                                               5322         3\n",
       "top     Managing Director 's comments : `` Net sales f...   neutral\n",
       "freq                                                    2      3130"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "885db85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence     5322\n",
       "Sentiment       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c306818c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     3130\n",
       "positive    1852\n",
       "negative     860\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cc70bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1e608e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[15,7],)\n",
    "plt.title('Count Plot for lable')\n",
    "sns.countplot(x = 'Sentiment', data = df, palette = 'hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60625e93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m explode \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m patches, texts, pcts \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mpie(\u001b[43mSentence\u001b[49m,\n\u001b[0;32m      6\u001b[0m                               Sentences \u001b[38;5;241m=\u001b[39m Sentences\u001b[38;5;241m.\u001b[39mindex,\n\u001b[0;32m      7\u001b[0m                               colors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      8\u001b[0m                               pctdistance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.65\u001b[39m,\n\u001b[0;32m      9\u001b[0m                               shadow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m                               startangle \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m90\u001b[39m,\n\u001b[0;32m     11\u001b[0m                               explode \u001b[38;5;241m=\u001b[39m explode,\n\u001b[0;32m     12\u001b[0m                               autopct \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%1.1f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m                               textprops\u001b[38;5;241m=\u001b[39m{ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfontsize\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m15\u001b[39m,\n\u001b[0;32m     14\u001b[0m                                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m                                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m                                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfamily\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserif\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39msetp(pcts, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m hfont \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfontname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserif\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sentence' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lable_data = df['Sentence'].value_counts()\n",
    "\n",
    "explode = (0.1, 0.1)\n",
    "plt.figure(figsize=(14, 10))\n",
    "patches, texts, pcts = plt.pie(Sentence,\n",
    "                              Sentences = Sentences.index,\n",
    "                              colors = ['blue', 'red'],\n",
    "                              pctdistance = 0.65,\n",
    "                              shadow = True,\n",
    "                              startangle = 90,\n",
    "                              explode = explode,\n",
    "                              autopct = '%1.1f%%',\n",
    "                              textprops={ 'fontsize': 15,\n",
    "                                         'color': 'black',\n",
    "                                         'weight': 'bold',\n",
    "                                        'family': 'serif'})\n",
    "plt.setp(pcts, color='black')\n",
    "hfont = {'fontname': 'serif', 'weight': 'bold'}\n",
    "plt.title('lable', size=45, **hfont)\n",
    "\n",
    "centre_circle = plt.Circle((0,0),0.40,fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e1d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c079bd91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mSentence\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mSentence\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mlower())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.Sentence=df.Sentence.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "50baf479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[', ,, ,, .]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[$, ,, $, ., $, .]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[,, ', ,, --, .]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-, ,, .]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[., ,, .]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>[]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>[-, .]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>[,, .]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>[,, ., %, ..]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>[-, ..]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5842 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sentence Sentiment\n",
       "0           [', ,, ,, .]  positive\n",
       "1     [$, ,, $, ., $, .]  negative\n",
       "2       [,, ', ,, --, .]  positive\n",
       "3              [-, ,, .]   neutral\n",
       "4              [., ,, .]   neutral\n",
       "...                  ...       ...\n",
       "5837                  []  negative\n",
       "5838              [-, .]   neutral\n",
       "5839              [,, .]   neutral\n",
       "5840       [,, ., %, ..]   neutral\n",
       "5841             [-, ..]  positive\n",
       "\n",
       "[5842 rows x 2 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "33da47f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'contractions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [120]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontractions\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'contractions'"
     ]
    }
   ],
   "source": [
    "# import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b4bd240c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [122]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     text\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39msub(pattern,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,text)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[1;32m----> 8\u001b[0m df\u001b[38;5;241m.\u001b[39mSentence\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_sp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [122]\u001b[0m, in \u001b[0;36mremove_sp\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_sp\u001b[39m(text):\n\u001b[0;32m      4\u001b[0m     pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[A-Za-z0-9\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m     text\u001b[38;5;241m=\u001b[39m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\re.py:210\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# import re\n",
    "\n",
    "# def remove_sp(text):\n",
    "#     pattern=r'[A-Za-z0-9\\s]'\n",
    "#     text=re.sub(pattern,'',text)\n",
    "#     return text\n",
    "\n",
    "# df.Sentence=df.Sentence.apply(remove_sp)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "41a63774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# punctuations=list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b5e51f88",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [115]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mSentence\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpunctuations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [115]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mSentence\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mSentence\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m() \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m punctuations))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# df.Sentence=df.Sentence.apply(lambda x : \" \".join(x for x in x.split() if x not in punctuations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "73086e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Removing stopwords\n",
    "nltk.download('stopwords')\n",
    "stopword_list=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7301f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword_list.remove('no')\n",
    "# stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7db88f50",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [113]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mSentence\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstopword_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentence\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m8\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [113]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mSentence\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mSentence\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m() \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopword_list))\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentence\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m8\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# df.Sentence=df.Sentence.apply(lambda x : \" \".join(x for x in x.split() if x not in stopword_list))\n",
    "# df['Sentence'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1d9d8442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e602d2b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [126]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_tokenize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentence\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py:107\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03mReturn a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03musing NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m:param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers/punkt/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1276\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, realign_boundaries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1273\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;124;03m    Given a text, returns a list of the sentences in that text.\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentences_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealign_boundaries\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1332\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.sentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, realign_boundaries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[s:e] \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1332\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, realign_boundaries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[s:e] \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1322\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.span_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m realign_boundaries:\n\u001b[0;32m   1321\u001b[0m     slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_realign_boundaries(text, slices)\n\u001b[1;32m-> 1322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m slices:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (sentence\u001b[38;5;241m.\u001b[39mstart, sentence\u001b[38;5;241m.\u001b[39mstop)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1421\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;124;03mAttempts to realign punctuation that falls after the period but\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;124;03mshould otherwise be included in the same sentence.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;124;03m    [\"(Sent1.)\", \"Sent2.\"].\u001b[39;00m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1420\u001b[0m realign \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1421\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence1, sentence2 \u001b[38;5;129;01min\u001b[39;00m _pair_iter(slices):\n\u001b[0;32m   1422\u001b[0m     sentence1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(sentence1\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m+\u001b[39m realign, sentence1\u001b[38;5;241m.\u001b[39mstop)\n\u001b[0;32m   1423\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sentence2:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:318\u001b[0m, in \u001b[0;36m_pair_iter\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    316\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterator)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1395\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_slices_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m   1394\u001b[0m     last_break \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1395\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m match, context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_match_potential_end_contexts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1396\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_contains_sentbreak(context):\n\u001b[0;32m   1397\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(last_break, match\u001b[38;5;241m.\u001b[39mend())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1375\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._match_potential_end_contexts\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1373\u001b[0m before_words \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1374\u001b[0m matches \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lang_vars\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperiod_context_re\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)):\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;66;03m# Ignore matches that have already been captured by matches to the right of this match\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m matches \u001b[38;5;129;01mand\u001b[39;00m match\u001b[38;5;241m.\u001b[39mend() \u001b[38;5;241m>\u001b[39m before_start:\n\u001b[0;32m   1378\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "df['Sentence']=df.Sentence.apply(word_tokenize)\n",
    "df['Sentence'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14195a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
